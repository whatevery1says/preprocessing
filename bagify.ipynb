{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words in a Dict\n",
      "{'Dear': 1, 'All': 1, 'hands': 2, 'meeting': 4, 'Friday': 1, 'April': 1, '26th': 1, '11': 1, '1': 1, 'Pacific': 1, 'focused': 1, 'developing': 1, 'prioritized': 1, 'list': 1, 'research': 2, 'questions': 3, 'summer': 2, 'camp': 1, 'use': 2, 'topic': 1, 'modeling': 1, 'address': 1, 'Please': 2, 'debriefing': 1, 'report': 1, 'includes': 1, 'ongoing': 1, 'tasks': 1, 'Important': 1, 'In': 1, 'advance': 1, 'collection': 1, 'teams': 2, 'interested': 1, 'Google': 1, 'sheet': 3, 'suggest': 1, 'high': 1, 'priority': 1, 'WE1S': 1, 'begin': 1, 'work': 1, 'We': 1, 'discuss': 1, 'prioritize': 1, 'links': 1, 'definition': 1, 'formed': 1, 'question': 1, 'previously': 1, 'suggested': 1, 'new': 1, 'feel': 1, 'important': 1, 'Also': 1, 'context': 1, 'promised': 1, 'outcomes': 1, 'Mellon': 1, 'grant': 1}\n",
      "\n",
      "\n",
      "All words except stop words\n",
      "['Dear', 'All', 'hands', 'meeting', 'Friday', 'April', '26th', '11', '1', 'Pacific', 'focused', 'developing', 'prioritized', 'list', 'research', 'questions', 'summer', 'camp', 'use', 'topic', 'modeling', 'address', 'Please', 'debriefing', 'report', 'hands', 'meeting', 'includes', 'ongoing', 'tasks', 'Important', 'In', 'advance', 'meeting', 'collection', 'teams', 'interested', 'use', 'Google', 'sheet', 'suggest', 'high', 'priority', 'research', 'questions', 'WE1S', 'begin', 'work', 'summer', 'We', 'discuss', 'prioritize', 'meeting', 'Please', 'links', 'sheet', 'definition', 'formed', 'question', 'previously', 'suggested', 'questions', 'new', 'sheet', 'teams', 'feel', 'important', 'Also', 'context', 'promised', 'outcomes', 'Mellon', 'grant']\n",
      "\n",
      "\n",
      "All nouns except stop words\n",
      "['hands', 'meeting', '26th', 'list', 'research', 'questions', 'summer', 'camp', 'topic', 'report', 'hands', 'meeting', 'tasks', 'advance', 'meeting', 'collection', 'teams', 'sheet', 'priority', 'research', 'questions', 'WE1S', 'summer', 'meeting', 'links', 'sheet', 'definition', 'question', 'questions', 'sheet', 'teams', 'context', 'outcomes', 'grant']\n",
      "\n",
      "\n",
      "Five most common words\n",
      "[('meeting', 4), ('questions', 3), ('sheet', 3), ('hands', 2), ('research', 2)]\n",
      "\n",
      "\n",
      "Noun frequencies\n",
      "{'hands': 2, 'meeting': 4, '26th': 1, 'list': 1, 'research': 2, 'questions': 3, 'summer': 2, 'camp': 1, 'topic': 1, 'report': 1, 'tasks': 1, 'advance': 1, 'collection': 1, 'teams': 2, 'sheet': 3, 'priority': 1, 'WE1S': 1, 'links': 1, 'definition': 1, 'question': 1, 'context': 1, 'outcomes': 1, 'grant': 1}\n",
      "\n",
      "\n",
      "Five most common nouns\n",
      "[('meeting', 4), ('questions', 3), ('sheet', 3), ('hands', 2), ('research', 2)]\n"
     ]
    }
   ],
   "source": [
    "str = \"\"\"Dear all, our next All-hands meeting will be Friday, April 26th, 11-1 (Pacific), and will be focused on developing a prioritized list of research questions that the summer camp will use topic modeling to address. (Please also see my debriefing report from our last all-hands meeting, which includes other ongoing tasks.)\n",
    "\n",
    "Important: In advance of the meeting, can each of the collection teams (and others who are interested) please use this Google sheet to suggest high-priority research questions that WE1S can begin to work on this summer? We will discuss and prioritize these at our meeting.\n",
    "\n",
    "Please see the links in the sheet to a definition of a well-formed question, and also to previously suggested questions (which can be put on the new sheet if teams feel they are important enough). Also, for context, see what we promised as outcomes for the Mellon grant\"\"\"\n",
    "\n",
    "import re\n",
    "str = re.sub('\\s+', ' ', str)\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(str)\n",
    "# all tokens that arent stop words or punctuations\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "# noun tokens that arent stop words or punctuations\n",
    "nouns = [token.text for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "\n",
    "# Bagify!\n",
    "word_freq = Counter(words)\n",
    "print('Bag of Words in a Dict')\n",
    "print(dict(word_freq))\n",
    "print('\\n')\n",
    "\n",
    "# Fun Stuff\n",
    "print('All words except stop words')\n",
    "print(words)\n",
    "print('\\n')\n",
    "\n",
    "print('All nouns except stop words')\n",
    "print(nouns)\n",
    "print('\\n')\n",
    "\n",
    "print('Five most common words')\n",
    "print(word_freq.most_common(5))\n",
    "print('\\n')\n",
    "\n",
    "print('Noun frequencies')\n",
    "noun_freq = Counter(nouns)\n",
    "print(dict(noun_freq))\n",
    "print('\\n')\n",
    "print('Five most common nouns')\n",
    "print(noun_freq.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
