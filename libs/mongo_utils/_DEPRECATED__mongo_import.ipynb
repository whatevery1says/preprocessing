{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WE1S data from zips to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient \n",
    "from pymongo.errors import DuplicateKeyError, InvalidDocument\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/jovyan/utils/preprocessing/')\n",
    "from libs.fuzzyhasher.fuzzyhasher import FuzzyHasher\n",
    "from libs.zipeditor.zipeditor import ZipEditor, zip_scanner, zip_scanner_excludedirs, ZipProcessor\n",
    "from we1s_utils.ziputils import BatchJSONUploader\n",
    "\n",
    "client = MongoClient('mongodb://mongo/')\n",
    "db = client['we1s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchJSONUploader2:\n",
    "    \"\"\"Processor takes a file path, iterates over JSON files,\n",
    "    and uploads to a mongodb database.\n",
    "    If a criteria matches, such as being listed in deletes\n",
    "    or a name matching cant or must, then a document is either\n",
    "    inserted (if a target collection is provided) or skipped.\n",
    "    If no rules match, then documents will be uploaded to the\n",
    "    default collection (if provided).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        default_collection,             # 'humanities-keywords'\n",
    "        deletes_collection='deletes',   # 'deletes-humanities'\n",
    "        deletes_file = '_deletes.txt',  # '_deletes.txt'\n",
    "        filter_collection='filter',     #\n",
    "        filter_name_cant='',            # 'no-exact-match'\n",
    "        filter_name_must=''\n",
    "        ):         # 'humanities-keywords-no-exact-match'\n",
    "\n",
    "        self.default_collection = default_collection\n",
    "        self.deletes_collection = deletes_collection\n",
    "        self.deletes_file = deletes_file\n",
    "        self.filter_collection = filter_collection\n",
    "        self.filter_name_cant = filter_name_cant\n",
    "        self.filter_name_must = filter_name_must\n",
    "\n",
    "    def get_json(json_path):\n",
    "        json_data = None\n",
    "        with open(json_path, 'r+') as f:\n",
    "            json_data = json.load(f)\n",
    "            json_data.pop('bag_of_words', None)\n",
    "        return json_data\n",
    "        \n",
    "    def do(self, files_path):\n",
    "        # create delete list\n",
    "        try:\n",
    "            with open(os.path.join(files_path, self.deletes_file), 'r') as f:\n",
    "                self.deletes_list = f.read().splitlines()\n",
    "        except OSError:\n",
    "            self.deletes_list = []\n",
    "        self.json_paths = [os.path.join(r, file) for r, d, f in os.walk(files_path) for file in f if file.endswith('.json') and not file.startswith('._')]\n",
    "        for json_path in self.json_paths:\n",
    "            try:\n",
    "                json_basename = os.path.split(json_path)[1]\n",
    "                if json_basename in self.deletes_list:\n",
    "                    if self.deletes_collection:\n",
    "                        self.deletes_collection.insert_one(get_json(json_path))\n",
    "                elif self.filter_name_must and self.filter_name_must not in json_basename:\n",
    "                    if self.filter_collection:\n",
    "                        self.filter_collection.insert_one(get_json(json_path))\n",
    "                elif self.filter_name_cant and self.filter_name_cant in json_basename:\n",
    "                    if self.filter_collection:\n",
    "                        self.filter_collection.insert_one(get_json(json_path))\n",
    "                elif self.default_collection:\n",
    "                    self.default_collection.insert_one(get_json(json_path))\n",
    "            except (json.decoder.JSONDecodeError, KeyError, PermissionError, ValueError, InvalidDocument) as err:\n",
    "                print('\\n', err.__class__.__name__, \": \", json_path, err)\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture output\n",
    "\n",
    "print('Import humanities_keywords and reddit')\n",
    "\n",
    "upload_list = []\n",
    "\n",
    "hum_zip_path_list = zip_scanner_excludedirs(\n",
    "    source_path='/home/jovyan/data/parsed/humanities-keywords/',\n",
    "    exclude_list=[''], join=True)\n",
    "hum_uploader = BatchJSONUploader2(\n",
    "    default_collection=db['humanities_keywords'],\n",
    "    deletes_file = '_deletes.txt',\n",
    "    deletes_collection=db['deletes_humanities'],\n",
    "    filter_name_cant='no-exact-match',\n",
    "    filter_name_must='',\n",
    "    filter_collection=db['humanities_keywords_no_exact'])\n",
    "upload_list.append(hum_zip_path_list, hum_uploader)\n",
    " \n",
    "rzip_path_list = zip_scanner_excludedirs(\n",
    "    source_path='/home/jovyan/data/parsed/reddit/',\n",
    "    exclude_list=[''], join=True)\n",
    "reddit_uploader = BatchJSONUploader2(\n",
    "    default_collection=db['reddit'],\n",
    "    deletes_file = '_deletes.txt',\n",
    "    deletes_collection=db['deletes_reddit'],\n",
    "    filter_name_cant='',\n",
    "    filter_name_must='',\n",
    "    filter_collection=db['deletes_reddit'])\n",
    "upload_list.append(rzip_path_list, reddit_uploader)\n",
    "\n",
    "for zip_path_list, uploader in scanner_lists:\n",
    "    for zip_path in zip_path_list:\n",
    "        zp = ZipProcessor(zip_path, uploader)\n",
    "        zp.process()\n",
    "        # print('...processed: ', zip_path)\n",
    "        # zp.open()\n",
    "        # x = os.listdir(zp.getdir())\n",
    "        # if '_deletes.txt' in x:\n",
    "        #     print(x)\n",
    "        #     print()\n",
    "        # zp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Import comparison corpus')\n",
    "\n",
    "comp_zip_path_list = zip_scanner_excludedirs(source_path='/home/jovyan/data/parsed/comparison-corpus/',\n",
    "                                        exclude_list=[''], join=True)\n",
    "comp_all_uploader = BatchJSONUploader2(\n",
    "    default_collection=db['comparison-not-humanities'],\n",
    "    deletes_file = '_deletes.txt',\n",
    "    deletes_collection=db['deletes_comparison-not-humanities'],\n",
    "    filter_name_cant='',\n",
    "    filter_name_must='no-exact-match',\n",
    "    filter_collection=db['comparison-not-humantiies-filter'])\n",
    "\n",
    "comp_science_uploader = BatchJSONUploader2(\n",
    "    default_collection=db['comparison-sciences'],\n",
    "    deletes_file = '_deletes.txt',\n",
    "    deletes_collection=db['deletes_comparison-sciences'],\n",
    "    filter_name_cant='no-exact-match',\n",
    "    filter_name_must='',\n",
    "    filter_collection=db['comparison-sciences-filter'])\n",
    "\n",
    "# The zips are mixed together in the list, so\n",
    "# two uploaders are used based on the filename:\n",
    "for zip_path in comp_zip_path_list:\n",
    "    if 'humanities_' in zip_path:\n",
    "        zp = ZipProcessor(zip_path, comp_all_uploader)\n",
    "        zp.process()\n",
    "    elif 'sciences_' in zip_path:\n",
    "        zp = ZipProcessor(zip_path, comp_science_uploader)\n",
    "        zp.process()\n",
    "    else:\n",
    "        print('...missed: ', zip_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
