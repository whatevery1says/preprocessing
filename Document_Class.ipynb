{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the language model, data source, and options\n",
    "\n",
    "model = 'en_core_web_sm'\n",
    "manifest_dir = 'data'\n",
    "manifest_file = '2006_08_humanities_student_major_0_reddit_com.json'\n",
    "options = {'merge_noun_chunks': False, 'merge_subtokens': False, 'collect_readability_scores': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *  \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "# Test for the spacy-readability module\n",
    "try:\n",
    "    from spacy_readability import Readability\n",
    "except:\n",
    "    msg = 'The spacy-readability module is not installed on your system, so readability scores will be unavailable unless you `pip install spacy-_readability`.'\n",
    "    print(msg)\n",
    "\n",
    "# The Document class\n",
    "class Document():\n",
    "    \"\"\"Model a document's features.\n",
    "\n",
    "    Parameters:\n",
    "    - manifest_dir: the path to the manifest directory\n",
    "    - manifest_file: the name of the manifest file.\n",
    "    - content_property: the name of the property from which to extract the content\n",
    "\n",
    "    Returns a JSON object with the format `{'response': 'success|fail', 'errors': []}`.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, manifest_dir, manifest_file, content_property, **kwargs):\n",
    "        \"\"\"Initialize the object.\"\"\"\n",
    "        self.manifest_filepath = os.path.join(manifest_dir, manifest_file)\n",
    "        self.manifest_dict = self._read_manifest()\n",
    "        self.manifest_json = json.dumps(self.manifest_dict, indent=2)\n",
    "        self.doc_string = self._get_docstring(content_property)\n",
    "        self.content = nlp(self.doc_string)\n",
    "        self.options = kwargs['kwargs']\n",
    "        self.feature_list = self.get_feature_list()\n",
    "        \n",
    "    def _read_manifest(self):\n",
    "        \"\"\"Read a JSON file and return a Python dict.\"\"\"\n",
    "        with open(self.manifest_filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.loads(f.read())\n",
    "        \n",
    "    def _get_docstring(self, content_property):\n",
    "        \"\"\"Extract a document string from a manifest property.\"\"\"\n",
    "        return self.manifest_dict[content_property]\n",
    "    \n",
    "    def get_feature_list(self):\n",
    "        \"\"\"Process the document with the spaCy pipeline.\n",
    "        \n",
    "        If `collect_readability_scores` is set, Flesch-Kincaid Readability,\n",
    "        Flesch-Kincaid Reading Ease and Dale-Chall formula scores are collected\n",
    "        in a tuple in that order. Other formulas are available (see \n",
    "        https://github.com/mholtzscher/spacy_readability).\n",
    "\n",
    "        Returns a list containing the document's feature set.\n",
    "        \"\"\"\n",
    "        # Handle optional pipes\n",
    "        if 'merge_noun_chunks' in self.options and self.options['merge_noun_chunks'] == True:\n",
    "            merge_nps = nlp.create_pipe('merge_noun_chunks')\n",
    "            nlp.add_pipe(merge_nps)\n",
    "        if 'merge_subtokens' in self.options and self.options['merge_subtokens'] == True:\n",
    "            merge_subtok = nlp.create_pipe('merge_subtokens')\n",
    "            nlp.add_pipe(merge_subtok)\n",
    "        if 'collect_readability_scores' in self.options and self.options['collect_readability_scores'] == True:\n",
    "            try:\n",
    "                nlp.add_pipe(Readability())\n",
    "            except:\n",
    "                pass\n",
    "            readability = (self.content._.flesch_kincaid_grade_level, self.content._.flesch_kincaid_reading_ease, self.content._.dale_chall)\n",
    "        # Build the feature list\n",
    "        feature_list = []\n",
    "        for token in self.content:\n",
    "            # Get named entity info (I=Inside, O=Outside, B=Begin)\n",
    "            ner = (token.ent_iob_, token.ent_type_)\n",
    "            t = [token.text, token.lemma_, token.pos_, token.tag_, ner]\n",
    "            if readability:\n",
    "                t.append(readability)\n",
    "            feature_list.append(tuple(t))\n",
    "        return feature_list\n",
    "    \n",
    "    def get_df(self):\n",
    "        \"\"\"Convert the list of features to a Pandas dataframe.\"\"\"\n",
    "        columns = ['Text', 'Lemma', 'POS', 'Tag', 'Entities']\n",
    "        if 'collect_readability_scores' in self.options and self.options['collect_readability_scores'] == True:\n",
    "            columns.append('Readability')\n",
    "        return pd.DataFrame(self.feature_list, columns=columns)\n",
    "    \n",
    "    def token_count(self, remove=[], pos=None):\n",
    "        \"\"\"Calculate number of tokens in the spaCy document.\n",
    "        \n",
    "        Parameters:\n",
    "        - remove: a list containing features to be removed ('punctuation', 'stopwords', or both)\n",
    "        - pos: a valid grammatical category to filter by (e.g. 'NOUN').\n",
    "        - as_counter: returns the result as a counter object\n",
    "\n",
    "        Returns a dict unless as_counter is set to `True`. This enables the following:\n",
    "        \"\"\"\n",
    "        is_punct = 'False'\n",
    "        is_stop = 'False'\n",
    "        if 'punctuation' in remove:\n",
    "            is_punct = True\n",
    "        if 'stopwords' in remove:\n",
    "            is_stop = True\n",
    "        if pos is not None:\n",
    "            tokens = [token.text for token in self.content if token.is_punct != is_punct and token.is_stop != is_stop and token.pos_ == pos]\n",
    "        else:\n",
    "            tokens = [token.text for token in self.content if token.is_punct != is_punct and token.is_stop != is_stop]\n",
    "        return len(tokens)\n",
    "\n",
    "    def get_lemmas(self, as_df=False):\n",
    "        \"\"\"Get a list of lemmas from the document.\n",
    "        \n",
    "        Parameters:\n",
    "        - as_df: return the list as a dataframe.\n",
    "        \"\"\"\n",
    "        lemmas = [token.lemma_ for token in self.content]\n",
    "        if as_df == True:\n",
    "            lemmas = pd.DataFrame(lemmas, columns=['Lemmas'])\n",
    "        return lemmas\n",
    "\n",
    "    def get_pos(self, as_df=False):\n",
    "        \"\"\"Get a list of parts of speech from the document.\n",
    "        \n",
    "        Parameters:\n",
    "        - as_df: return the list as a dataframe.\n",
    "        \"\"\"\n",
    "        pos = [token.pos_ for token in self.content]\n",
    "        if as_df == True:\n",
    "            pos = pd.DataFrame(pos, columns=['POS'])\n",
    "        return pos\n",
    "\n",
    "    def get_tags(self, as_df=False):\n",
    "        \"\"\"Get a list of grammatical tags from the document.\n",
    "        \n",
    "        Parameters:\n",
    "        - as_df: return the list as a dataframe.\n",
    "        \"\"\"\n",
    "        tags = [token.tag_ for token in self.content]\n",
    "        if as_df == True:\n",
    "            tags = pd.DataFrame(tags, columns=['Tags'])\n",
    "        return tags\n",
    "\n",
    "    def get_entities(self, options=['text', 'label'], as_df=False):\n",
    "        \"\"\"Get a list of entities from the document.\n",
    "        \n",
    "        Parameters:\n",
    "        - options: a list of attributes ('text', 'start', 'end', 'label')\n",
    "        - as_df: return the list as a dataframe.\n",
    "        \"\"\"\n",
    "        ents = []\n",
    "        for ent in self.content.ents:\n",
    "            e = []\n",
    "            if 'text' in options:\n",
    "                e.append(ent.text)\n",
    "            if 'start' in options:\n",
    "                e.append(ent.start)\n",
    "            if 'end' in options:\n",
    "                e.append(ent.end)\n",
    "            if 'label' in options:\n",
    "                e.append(ent.label_)\n",
    "            ents.append(tuple(e))\n",
    "        if as_df == True:\n",
    "            ents = pd.DataFrame(ents, columns=[option.title() for option in options])\n",
    "        return ents\n",
    "\n",
    "    def get_readability_scores(self, columns=['Flesch-Kincaid Readability',\n",
    "        'Flesch-Kincaid Reading Ease', 'Dale-Chall'], as_df=False):\n",
    "        \"\"\"Get a list of readability scores from the document.\n",
    "        \n",
    "        Parameters:\n",
    "        - columns: a list of labels for the score types\n",
    "        - as_df: return the list as a dataframe.\n",
    "        \"\"\"\n",
    "        tuples = self.get_df()['Readability'].values\n",
    "        scores = []\n",
    "        for score in tuples:\n",
    "            scores.append(list(score))\n",
    "        if as_df == True:\n",
    "            scores = pd.DataFrame(scores, columns=columns)\n",
    "        return scores\n",
    "\n",
    "    def bagify(self, remove=[], pos=None, as_counter=False):\n",
    "        \"\"\"Convert a spaCy document into a dict containing feature frequencies.\n",
    "\n",
    "        Parameters:\n",
    "        - remove: a list containing features to be removed ('punctuation', 'stopwords', or both)\n",
    "        - pos: a valid grammatical category to filter by (e.g. 'NOUN').\n",
    "        - as_counter: returns the result as a counter object\n",
    "\n",
    "        Returns a dict unless as_counter is set to `True`. This enables the following:\n",
    "        \n",
    "        `bag = features.bagify(as_counter=True).most_common(10)`\n",
    "        \"\"\"\n",
    "        # Boolean False is not accepted for some reason\n",
    "        is_punct = 'False'\n",
    "        is_stop = 'False'\n",
    "        if 'punctuation' in remove:\n",
    "            is_punct = True\n",
    "        if 'stopwords' in remove:\n",
    "            is_stop = True\n",
    "        if pos is not None:\n",
    "            bag = [token.text for token in self.content if token.is_punct != is_punct and token.is_stop != is_stop and token.pos_ == pos]\n",
    "        else:\n",
    "            bag = [token.text for token in self.content if token.is_punct != is_punct and token.is_stop != is_stop]\n",
    "        if as_counter == True:\n",
    "            return Counter(bag)\n",
    "        else:\n",
    "            return dict(Counter(bag))\n",
    "\n",
    "    def get_stems(self, stemmer='porter', as_df=True):\n",
    "        \"\"\"Convert the tokens in a spaCy document to stems.\n",
    "\n",
    "        Parameters:\n",
    "        - stemmer: the stemming algorithm ('porter' or 'snowball').\n",
    "        - as_df: return the list as a dataframe.\n",
    "\n",
    "        Returns a list of stems or a dataframe.\n",
    "        \"\"\"\n",
    "        if stemmer == 'snowball':\n",
    "            stemmer = SnowballStemmer(language='english')\n",
    "        else:\n",
    "            stemmer = PorterStemmer()\n",
    "        stems = [stemmer.stem(token.text) for token in self.content]\n",
    "        if as_df == True:\n",
    "            stems = pd.DataFrame(stems, columns=['Stems'])\n",
    "        return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the feature table\n",
    "doc = Document(manifest_dir, manifest_file, 'content_scrubbed', kwargs=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ideas</td>\n",
       "      <td>idea</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>replacing</td>\n",
       "      <td>replace</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'ll</td>\n",
       "      <td>will</td>\n",
       "      <td>VERB</td>\n",
       "      <td>MD</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bite</td>\n",
       "      <td>bite</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>(B, CARDINAL)</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>More</td>\n",
       "      <td>more</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJR</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>academics</td>\n",
       "      <td>academic</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>expressing</td>\n",
       "      <td>express</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>notion</td>\n",
       "      <td>notion</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>degree</td>\n",
       "      <td>degree</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>certain</td>\n",
       "      <td>certain</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>age</td>\n",
       "      <td>age</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>That[.</td>\n",
       "      <td>that[.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>top</td>\n",
       "      <td>top</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>my</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>might</td>\n",
       "      <td>may</td>\n",
       "      <td>VERB</td>\n",
       "      <td>MD</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>post</td>\n",
       "      <td>post</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>more</td>\n",
       "      <td>more</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RBR</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>if</td>\n",
       "      <td>if</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>come</td>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>PART</td>\n",
       "      <td>RP</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>anything</td>\n",
       "      <td>anything</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>Is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>(O, )</td>\n",
       "      <td>(7.039373695386168, 70.15675434571368, 7.96144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Text     Lemma    POS    Tag       Entities  \\\n",
       "0          Ideas      idea   NOUN    NNS          (O, )   \n",
       "1            for       for    ADP     IN          (O, )   \n",
       "2      replacing   replace   VERB    VBG          (O, )   \n",
       "3             it    -PRON-   PRON    PRP          (O, )   \n",
       "4              ?         ?  PUNCT      .          (O, )   \n",
       "5           Yeah      yeah   INTJ     UH          (O, )   \n",
       "6              ,         ,  PUNCT      ,          (O, )   \n",
       "7              I    -PRON-   PRON    PRP          (O, )   \n",
       "8            'll      will   VERB     MD          (O, )   \n",
       "9           bite      bite   VERB     VB          (O, )   \n",
       "10             .         .  PUNCT      .          (O, )   \n",
       "11          \\n\\n      \\n\\n  SPACE    _SP          (O, )   \n",
       "12             1         1    NUM     CD  (B, CARDINAL)   \n",
       "13             .         .  PUNCT      .          (O, )   \n",
       "14          More      more    ADJ    JJR          (O, )   \n",
       "15     academics  academic   NOUN    NNS          (O, )   \n",
       "16           and       and  CCONJ     CC          (O, )   \n",
       "17        people    people   NOUN    NNS          (O, )   \n",
       "18            in        in    ADP     IN          (O, )   \n",
       "19           the       the    DET     DT          (O, )   \n",
       "20      business  business   NOUN     NN          (O, )   \n",
       "21         world     world   NOUN     NN          (O, )   \n",
       "22    expressing   express   VERB    VBG          (O, )   \n",
       "23           the       the    DET     DT          (O, )   \n",
       "24        notion    notion   NOUN     NN          (O, )   \n",
       "25          that      that    ADP     IN          (O, )   \n",
       "26             a         a    DET     DT          (O, )   \n",
       "27        degree    degree   NOUN     NN          (O, )   \n",
       "28            is        be   VERB    VBZ          (O, )   \n",
       "29             a         a    DET     DT          (O, )   \n",
       "...          ...       ...    ...    ...            ...   \n",
       "1462     certain   certain    ADJ     JJ          (O, )   \n",
       "1463         age       age   NOUN     NN          (O, )   \n",
       "1464           .         .  PUNCT      .          (O, )   \n",
       "1465        \\n\\n      \\n\\n  SPACE    _SP          (O, )   \n",
       "1466      That[.    that[.  PROPN    NNP          (O, )   \n",
       "1467           ]         ]  PUNCT  -RRB-          (O, )   \n",
       "1468         the       the    DET     DT          (O, )   \n",
       "1469         top       top   NOUN     NN          (O, )   \n",
       "1470          of        of    ADP     IN          (O, )   \n",
       "1471          my    -PRON-    ADJ   PRP$          (O, )   \n",
       "1472        head      head   NOUN     NN          (O, )   \n",
       "1473           .         .  PUNCT      .          (O, )   \n",
       "1474           I    -PRON-   PRON    PRP          (O, )   \n",
       "1475       might       may   VERB     MD          (O, )   \n",
       "1476        post      post   VERB     VB          (O, )   \n",
       "1477        more      more    ADV    RBR          (O, )   \n",
       "1478        here      here    ADV     RB          (O, )   \n",
       "1479          if        if    ADP     IN          (O, )   \n",
       "1480           I    -PRON-   PRON    PRP          (O, )   \n",
       "1481        come      come   VERB    VBP          (O, )   \n",
       "1482          up        up   PART     RP          (O, )   \n",
       "1483        with      with    ADP     IN          (O, )   \n",
       "1484    anything  anything   NOUN     NN          (O, )   \n",
       "1485           .         .  PUNCT      .          (O, )   \n",
       "1486          Is        be   VERB    VBZ          (O, )   \n",
       "1487        that      that    DET     DT          (O, )   \n",
       "1488           a         a    DET     DT          (O, )   \n",
       "1489        good      good    ADJ     JJ          (O, )   \n",
       "1490       start     start   NOUN     NN          (O, )   \n",
       "1491           ?         ?  PUNCT      .          (O, )   \n",
       "\n",
       "                                            Readability  \n",
       "0     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "2     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "3     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "4     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "5     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "6     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "7     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "8     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "9     (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "10    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "11    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "12    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "13    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "14    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "15    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "16    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "17    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "18    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "19    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "20    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "21    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "22    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "23    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "24    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "25    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "26    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "27    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "28    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "29    (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "...                                                 ...  \n",
       "1462  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1463  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1464  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1465  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1466  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1467  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1468  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1469  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1470  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1471  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1472  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1473  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1474  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1475  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1476  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1477  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1478  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1479  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1480  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1481  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1482  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1483  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1484  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1485  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1486  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1487  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1488  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1489  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1490  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "1491  (7.039373695386168, 70.15675434571368, 7.96144...  \n",
       "\n",
       "[1492 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Uncomment lines below to try various class methods.\n",
    "## See the method docstrings for options not shown in the examples below.\n",
    "\n",
    "# Get all the doc features in a dataframe\n",
    "doc.get_df()\n",
    "\n",
    "# Same thing, except return a list of tuples\n",
    "# # doc.get_feature_list()\n",
    "\n",
    "# Get lemmas\n",
    "# doc.get_lemmas(as_df=True)\n",
    "\n",
    "# Get entities\n",
    "# doc.get_entities(as_df=True)\n",
    "\n",
    "# Get Stems\n",
    "# doc.get_stems(stemmer='porter', as_df=True)\n",
    "\n",
    "# Get readability scores\n",
    "# doc.get_readability_scores(as_df=True)\n",
    "\n",
    "# Bagify\n",
    "# doc.bagify()\n",
    "\n",
    "# Get most common nouns\n",
    "# doc.bagify(pos='NOUN', as_counter=True).most_common(5)\n",
    "\n",
    "# Get a count of all tokens\n",
    "# doc.token_count(remove=['punctuation', 'stopwords'])\n",
    "\n",
    "# Get the original document text\n",
    "# doc.doc_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "- Method to add a column (e.g. stems) to the feature list.\n",
    "- Methods to update the document manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
